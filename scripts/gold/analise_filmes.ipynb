{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c482af-f381-4866-a64e-807b140bd7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delta-spark==2.4.0 in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: pyspark<3.5.0,>=3.4.0 in /usr/local/spark/python (from delta-spark==2.4.0) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark==2.4.0) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark==2.4.0) (3.16.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark<3.5.0,>=3.4.0->delta-spark==2.4.0) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install dependencies if needed\n",
    "!pip install delta-spark==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa1c09b-f798-4cec-b75a-0dda079bf1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark iniciado com sucesso — versão: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import necessary modules and start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, trim, regexp_replace, broadcast\n",
    "from delta import *\n",
    "\n",
    "# Caminho do warehouse Hive no HDFS\n",
    "warehouse_location = \"hdfs://hdfs-nn:9000/warehouse\"\n",
    "\n",
    "# Criação da sessão Spark com suporte a Hive + Delta Lake\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Gold_Analise_Filmes\")\n",
    "    # ---- configurações Hive ----\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location)\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "    .config(\"hive.metastore.warehouse.dir\", warehouse_location)\n",
    "    # ---- extensões Delta Lake ----\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    # ---- pacote Delta compatível com Spark 3.4.1 (Scala 2.12) ----\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark iniciado com sucesso — versão:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6ba57f-5859-43d1-a7f5-77a320e2d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de dados 'gold' pronta.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create gold database if not exists\n",
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS gold\n",
    "    LOCATION 'hdfs://hdfs-nn:9000/warehouse/gold.db'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Base de dados 'gold' pronta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6131936b-6d90-4335-b85b-9605029973d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas silver carregadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load silver tables\n",
    "boxoffice_df = spark.table(\"silver.boxoffice\")\n",
    "adaptations_df = spark.table(\"silver.adaptations\")\n",
    "actorfilms_df = spark.table(\"silver.actorfilms\")\n",
    "rating_movies_df = spark.table(\"silver.rating_movies\")\n",
    "\n",
    "print(\"Tabelas silver carregadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b3b09d-75f3-48ca-9a05-4f4aa488b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Primeiro join: adaptations com rating_movies\n",
    "# Join em movie_title_norm == title_norm e movie_year == release_year\n",
    "# Usar broadcast na menor (adaptations)\n",
    "joined_adapt_rating = (\n",
    "    adaptations_df\n",
    "    .join(\n",
    "        broadcast(rating_movies_df),\n",
    "        (adaptations_df.title== rating_movies_df.title_norm) &\n",
    "        (adaptations_df.release_year == rating_movies_df.release_year),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        adaptations_df.author,\n",
    "        adaptations_df.book_title,\n",
    "        adaptations_df.title,\n",
    "        adaptations_df.release_year,\n",
    "        rating_movies_df.writers,\n",
    "        rating_movies_df.rating,\n",
    "        rating_movies_df.tomatometer_status,\n",
    "        rating_movies_df.tomatometer_rating,\n",
    "        rating_movies_df.tomatometer_count,\n",
    "        rating_movies_df.audience_rating,\n",
    "        rating_movies_df.audience_count,\n",
    "        rating_movies_df.critics_consensus,\n",
    "        rating_movies_df.cast\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a0d738-beda-4505-94ce-534fb569f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Segundo join: resultado anterior com boxoffice\n",
    "# Join em movie_title_norm == title e movie_year == year\n",
    "# Usar broadcast na boxoffice (provavelmente pequena)\n",
    "joined_adapt_rating_box = (\n",
    "    joined_adapt_rating\n",
    "    .join(\n",
    "        broadcast(boxoffice_df),\n",
    "        (joined_adapt_rating.title == boxoffice_df.title) &\n",
    "        (joined_adapt_rating.release_year == boxoffice_df.year),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        joined_adapt_rating.author,\n",
    "        joined_adapt_rating.book_title,\n",
    "        joined_adapt_rating.title,\n",
    "        joined_adapt_rating.release_year,\n",
    "        joined_adapt_rating.writers,\n",
    "        joined_adapt_rating.rating,\n",
    "        joined_adapt_rating.tomatometer_status,\n",
    "        joined_adapt_rating.tomatometer_rating,\n",
    "        joined_adapt_rating.tomatometer_count,\n",
    "        joined_adapt_rating.audience_rating,\n",
    "        joined_adapt_rating.audience_count,\n",
    "        joined_adapt_rating.critics_consensus,\n",
    "        joined_adapt_rating.cast,\n",
    "        boxoffice_df.gross,\n",
    "        boxoffice_df.decade\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4717d9cc-8f4f-4914-bfbb-0f51e406745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Terceiro join: resultado anterior com actorfilms\n",
    "# Primeiro, normalizar o título no actorfilms (já que não está normalizado)\n",
    "# Join em movie_title_norm == title_norm e movie_year == year\n",
    "# Usar broadcast no resultado anterior (deve ser pequeno agora)\n",
    "\n",
    "from pyspark.sql.functions import col, lower , trim , regexp_replace , broadcast\n",
    "actorfilms_norm_df = (\n",
    "    actorfilms_df\n",
    "    .withColumn(\"title\", lower(trim(regexp_replace(col(\"title\"), r\"[^a-z0-9 ]\", \"\"))))\n",
    ")\n",
    "\n",
    "gold_analise_filmes_df = (\n",
    "    joined_adapt_rating_box\n",
    "    .join(\n",
    "        broadcast(actorfilms_norm_df),\n",
    "        (joined_adapt_rating_box.title == actorfilms_norm_df.title) &\n",
    "        (joined_adapt_rating_box.release_year == actorfilms_norm_df.year),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        joined_adapt_rating_box.author,\n",
    "        joined_adapt_rating_box.book_title,\n",
    "        joined_adapt_rating_box.title,\n",
    "        joined_adapt_rating_box.release_year,\n",
    "        joined_adapt_rating_box.writers,\n",
    "        joined_adapt_rating_box.rating,\n",
    "        joined_adapt_rating_box.tomatometer_status,\n",
    "        joined_adapt_rating_box.tomatometer_rating,\n",
    "        joined_adapt_rating_box.tomatometer_count,\n",
    "        joined_adapt_rating_box.audience_rating,\n",
    "        joined_adapt_rating_box.audience_count,\n",
    "        joined_adapt_rating_box.critics_consensus,\n",
    "        joined_adapt_rating_box.cast,\n",
    "        joined_adapt_rating_box.gross,\n",
    "        joined_adapt_rating_box.decade,\n",
    "        actorfilms_norm_df.actor,\n",
    "        actorfilms_norm_df.votes,\n",
    "        actorfilms_norm_df.rating.alias(\"actor_rating\"),  # Renomear para evitar conflito com outra rating\n",
    "        actorfilms_norm_df.film_id,\n",
    "        actorfilms_norm_df.actor_id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795ca6f-598e-49fa-9214-87bfe7cb065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Write to gold.analise_filmes as Delta table\n",
    "(\n",
    "    gold_analise_filmes_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", True)\n",
    "    .option(\"path\", \"hdfs://hdfs-nn:9000/warehouse/gold.db/analise_filmes\")\n",
    "    .saveAsTable(\"gold.analise_filmes\")\n",
    ")\n",
    "\n",
    "print(\"Tabela gold.analise_filmes gravada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39331b88-18d2-4855-ab14-c198e08ffb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Verify the gold table\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM gold.analise_filmes LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b208e8-52be-4504-94a2-a0fda9aaf189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col\n",
    "\n",
    "df = spark.table(\"gold.analise_filmes\")\n",
    "\n",
    "df.coalesce(1) \\\n",
    "  .write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .csv(\"/tmp/analus_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52934efd-449a-4b3f-b9a5-bf276c9666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
